{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79403d5a-6532-4207-88a9-356f6e192eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark ê¸°ë°˜ ëª¹ ë“œë¡­ ê°€ì¹˜ ì˜ˆì¸¡ ëª¨ë¸ (ì„ í˜• íšŒê·€ with íŒŒì´í”„ë¼ì¸ ì „ì²´ êµ¬ì„±)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, sum as spark_sum\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1. Spark ì„¸ì…˜ ìƒì„±\n",
    "spark = SparkSession.builder.appName(\"MobDropValueRegression\").getOrCreate()\n",
    "\n",
    "# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "mobs = spark.read.csv('../learning_spark_data/minecraft/Mobs.csv', header=True, inferSchema=True)\n",
    "food = spark.read.csv('../learning_spark_data/minecraft/Food.csv', header=True, inferSchema=True)\n",
    "mob_food = spark.read.csv('../learning_spark_data/minecraft/MobFoodDrops.csv', header=True, inferSchema=True)\n",
    "\n",
    "# 3. ë“œë¡­ ê°€ì¹˜ ê³„ì‚°: foodID ê¸°ì¤€ìœ¼ë¡œ hunger í•©ì‚°\n",
    "drop_value = mob_food.join(food.withColumnRenamed(\"ID\", \"foodID\").select(\"foodID\", \"hunger\"), on=\"foodID\", how=\"left\")\n",
    "value_per_mob = drop_value.groupBy(\"mobID\").agg(spark_sum(\"hunger\").alias(\"totalDropValue\"))\n",
    "\n",
    "# 4. mobsì™€ joiní•˜ì—¬ ì „ì²´ mob ì •ë³´ì— ë“œë¡­ ê°€ì¹˜ ì¶”ê°€\n",
    "mob_all = mobs.join(value_per_mob, mobs[\"ID\"] == value_per_mob[\"mobID\"], how=\"left\")\n",
    "mob_all = mob_all.withColumn(\"totalDropValue\", when(col(\"totalDropValue\").isNull(), 0).otherwise(col(\"totalDropValue\")))\n",
    "\n",
    "# 5. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§: í•„ìš” ì»¬ëŸ¼ ì„ íƒ\n",
    "features = [\"healthPoints\", \"maxDamage\"]\n",
    "\n",
    "# 6. Null ê°’ ì²˜ë¦¬ (0ìœ¼ë¡œ ëŒ€ì²´)\n",
    "for f in features:\n",
    "    mob_all = mob_all.withColumn(f, when(col(f).isNull(), 0).otherwise(col(f)))\n",
    "\n",
    "# 7. VectorAssembler + í‘œì¤€í™” (StandardScaler)\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"assembled\")\n",
    "scaler = StandardScaler(inputCol=\"assembled\", outputCol=\"features\")\n",
    "\n",
    "# 8. ì„ í˜• íšŒê·€ ëª¨ë¸ ì •ì˜\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"totalDropValue\")\n",
    "\n",
    "# 9. íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "stages = [assembler, scaler, lr]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# 10. ë°ì´í„° ë¶„í•  (train/test)\n",
    "train_data, test_data = mob_all.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 11. íŒŒì´í”„ë¼ì¸ í•™ìŠµ ë° ë³€í™˜\n",
    "fitted_transform = pipeline.fit(train_data)\n",
    "vtrain_data = fitted_transform.transform(train_data)\n",
    "vtrain_data.printSchema()\n",
    "\n",
    "# 12. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "predictions = fitted_transform.transform(test_data)\n",
    "final_model = fitted_transform.stages[-1]  # LinearRegressionModel\n",
    "summary = final_model.evaluate(predictions)\n",
    "\n",
    "# 13. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nðŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ì¤€)\")\n",
    "print(f\"- íšŒê·€ ê³„ìˆ˜ (slope): {final_model.coefficients}\")\n",
    "print(f\"- ì ˆíŽ¸ (intercept): {final_model.intercept:.4f}\")\n",
    "print(f\"- R^2 (ì„¤ëª…ë ¥): {summary.r2:.4f}\")\n",
    "print(f\"- RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): {summary.rootMeanSquaredError:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1872aba-0bfa-41bf-84ac-81fa1aeb506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, sum as spark_sum\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1. Spark ì„¸ì…˜ ìƒì„±\n",
    "spark = SparkSession.builder.appName(\"MobDropValueRegression\").getOrCreate()\n",
    "\n",
    "# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "mobs = spark.read.csv('../learning_spark_data/minecraft/Mobs.csv', header=True, inferSchema=True)\n",
    "food = spark.read.csv('../learning_spark_data/minecraft/Food.csv', header=True, inferSchema=True)\n",
    "mob_food = spark.read.csv('../learning_spark_data/minecraft/MobFoodDrops.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da0a06d-e0c1-453f-bc7e-363a1c91f3b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771bd35-1a04-4a71-b544-e81c828ae6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
